{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTeZLH6LDFTVjHC8utCx6Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koushik980/NLP/blob/main/NLP_F_25_09_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFNE2LZn8NkD",
        "outputId": "a4f1314e-3492-42a3-8d1c-62784fd0ae91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No dataset found at the configured paths.\n",
            "If you'd like to upload a file from your computer, run the code below in a new cell:\n",
            "from google.colab import files\n",
            "uploaded = files.upload()\n",
            "# then set DATA_PATH to the uploaded filename\n",
            "No dataset found. Auto-creating a synthetic 'tweets.csv' for testing (balanced, 1000 rows).\n",
            "Synthetic dataset saved to: tweets.csv\n",
            "Loaded 1000 rows from tweets.csv\n",
            "                                tweet  label\n",
            "0  Terrible experience , never again.      0\n",
            "1              Frustrating and buggy       0\n",
            "2                       I love this!       1\n",
            "3                       I love this!       1\n",
            "4    Awful service , not recommended.      0\n"
          ]
        }
      ],
      "source": [
        "# ---------- Robust data loading (replace previous load section) ----------\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# set this to your preferred path or leave as-is\n",
        "DATA_PATH = '/path/to/your/sentiment_analysis_data.csv'  # edit if you have a custom path\n",
        "FALLBACK_NAME = 'tweets.csv'  # common fallback\n",
        "AUTO_CREATE_SAMPLE = True     # if True and no file found, generate a synthetic sample\n",
        "\n",
        "def create_synthetic_tweets_csv(path='tweets.csv', n=1000, seed=42):\n",
        "    \"\"\"Create a balanced synthetic tweets.csv with n samples (n should be even).\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    n = int(n // 2) * 2  # ensure even\n",
        "    pos_templates = [\n",
        "        \"I love this! {}\",\n",
        "        \"Amazing product {}, would buy again!\",\n",
        "        \"This made my day {}\",\n",
        "        \"So happy with the results {}\",\n",
        "        \"Absolutely fantastic experience {}\",\n",
        "        \"Great job, very satisfied {}\",\n",
        "        \"Highly recommend this {}\",\n",
        "        \"Five stars! {}\",\n",
        "        \"So good, impressed {}\",\n",
        "        \"Loved every bit of it {}\"\n",
        "    ]\n",
        "    neg_templates = [\n",
        "        \"Terrible experience {}, never again.\",\n",
        "        \"Very disappointed {}\",\n",
        "        \"Worst purchase ever {}\",\n",
        "        \"This ruined my day {}\",\n",
        "        \"Completely useless {}, do not buy.\",\n",
        "        \"Awful service {}, not recommended.\",\n",
        "        \"Regret buying this {}\",\n",
        "        \"One star {}, poor quality.\",\n",
        "        \"Frustrating and buggy {}\",\n",
        "        \"Not worth the money {}\"\n",
        "    ]\n",
        "    rows = []\n",
        "    for i in range(n // 2):\n",
        "        rows.append({\"tweet\": pos_templates[i % len(pos_templates)].format(\"\"), \"label\": 1})\n",
        "        rows.append({\"tweet\": neg_templates[i % len(neg_templates)].format(\"\"), \"label\": 0})\n",
        "    df_sample = pd.DataFrame(rows)\n",
        "    df_sample = df_sample.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
        "    df_sample.to_csv(path, index=False)\n",
        "    return df_sample\n",
        "\n",
        "# Try to load dataset with helpful fallback and clear error messages\n",
        "df = None\n",
        "\n",
        "if os.path.exists(DATA_PATH):\n",
        "    print(f\"✔ Found dataset at DATA_PATH: {DATA_PATH}\")\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "elif os.path.exists(FALLBACK_NAME):\n",
        "    print(f\"✔ Found dataset at fallback path: {FALLBACK_NAME}\")\n",
        "    DATA_PATH = FALLBACK_NAME\n",
        "    df = pd.read_csv(FALLBACK_NAME)\n",
        "else:\n",
        "    # If running in Google Colab, allow upload\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"No dataset found at the configured paths.\")\n",
        "        print(\"If you'd like to upload a file from your computer, run the code below in a new cell:\")\n",
        "        print(\"from google.colab import files\\nuploaded = files.upload()\\n# then set DATA_PATH to the uploaded filename\")\n",
        "    except Exception:\n",
        "        # not Colab or files.upload not available - ignore\n",
        "        pass\n",
        "\n",
        "    if AUTO_CREATE_SAMPLE:\n",
        "        print(\"No dataset found. Auto-creating a synthetic 'tweets.csv' for testing (balanced, 1000 rows).\")\n",
        "        df = create_synthetic_tweets_csv(path=FALLBACK_NAME, n=1000, seed=42)\n",
        "        DATA_PATH = FALLBACK_NAME\n",
        "        print(f\"Synthetic dataset saved to: {FALLBACK_NAME}\")\n",
        "    else:\n",
        "        raise FileNotFoundError(\n",
        "            f\"Data file not found at '{DATA_PATH}' or '{FALLBACK_NAME}'.\\n\"\n",
        "            \"Either upload a CSV file (use files.upload() in Colab), or set DATA_PATH to the correct path.\"\n",
        "        )\n",
        "\n",
        "# Validate required columns\n",
        "REQUIRED_COLS = ['tweet', 'label']\n",
        "for col in REQUIRED_COLS:\n",
        "    if col not in df.columns:\n",
        "        raise ValueError(f\"Dataset missing required column '{col}'. Found columns: {list(df.columns)}\")\n",
        "\n",
        "print(f\"Loaded {len(df)} rows from {DATA_PATH}\")\n",
        "# optional: show head\n",
        "print(df.head())\n",
        "\n",
        "# Now continue with your pipeline; e.g.:\n",
        "# df['clean'] = df['tweet'].astype(str).apply(clean_text)"
      ]
    }
  ]
}